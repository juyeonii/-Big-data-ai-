{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < Getting Started with Images >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Read Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.imread(filename, flag)\n",
    "\n",
    "- flag = cv2.IMREAD_COLOR : Loads a color image. (1) \n",
    "- flag = cv2.IMREAD_GRAYSCALE : Loads image in grayscale mode (0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"./data/opencv-4.1-feature-image.png\", cv2.IMREAD_COLOR)\n",
    "img = cv2.imread(\"./data/opencv-4.1-feature-image.png\")\n",
    "# img = cv2.imread(\"https://opencv.org/wp-content/uploads/2019/04/opencv-4.1-feature-image.png\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Display Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cv2.imshow(window title, array) # Display an image in a window\n",
    "\n",
    "- cv2.waitKey(delay) #Waits for specified milliseconds for any keyboard event\n",
    "\n",
    "- cv2.destroyAllWindows() #Destroys all the windows created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', img)\n",
    "k = cv2.waitKey(0)\n",
    "if k == 27:         # wait for ESC key to exit\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Matplotlib\n",
    "- Matplotlib is a plotting library for Python which gives you wide variety of plotting methods.\n",
    "\n",
    "- cv2.cvtColor(img, flag) #Convert Color space BGR to RGB\n",
    "\n",
    "- plt.imshow(ung) #Display an image in a jupyter notebook cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cvt_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(cvt_img)\n",
    "#plt.imshow(img)\n",
    "#plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Image Data information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- img.shape #print image dimension\n",
    "- img.size # The number of all elements image array\n",
    "- img.dtype # Data type of image array\n",
    "- img[y,x] # Pixel value of image (y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvt_img.shape)\n",
    "print(cvt_img.size)\n",
    "print(cvt_img.dtype)\n",
    "print(cvt_img[50,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do\n",
    "red_pixel = cvt_img[50,100]\n",
    "green_pixel = cvt_img[150,60]\n",
    "blue_pixel = cvt_img[150,170]\n",
    "white_pixel = cvt_img[10,10] \n",
    "black_pixel = cvt_img[220,75]\n",
    "\n",
    "\n",
    "print(\"red pixel :\", red_pixel)\n",
    "print(\"green pixel :\", green_pixel)\n",
    "print(\"blue pixel :\", blue_pixel)\n",
    "print(\"white pixel :\", white_pixel)\n",
    "print(\"black pixel :\", black_pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Drawing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing Functions have some common arguments as given below:\n",
    "\n",
    "- img : The image where you want to draw the shapes\n",
    "- color : Color of the shape. For grayscale, just pass the scalar value.\n",
    "- thickness : Thickness of the line or circle etc.\n",
    "- lineType : Type of line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_img = np.full((512, 512, 3), 255, np.uint8)\n",
    "# drawing_img = np.zeros((512, 512, 3), np.uint8)\n",
    "# drawing_img += 255\n",
    "\n",
    "plt.imshow(drawing_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.line(img, start, end, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_img = np.full((512, 512, 3), 255, np.uint8)\n",
    "cv2.line(drawing_img, (200, 0), (511, 511), (0, 255, 0), 10) #(x,y) 좌표\n",
    "plt.imshow(drawing_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.rectangle(img, start, end, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_img = np.full((512, 512, 3), 255, np.uint8)\n",
    "cv2.rectangle(drawing_img, (30, 30), (100, 200), (255, 0, 0), 10) #(x,y) 좌표\n",
    "plt.imshow(drawing_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.circle(img, center, radian, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_img = np.full((512, 512, 3), 255, np.uint8)\n",
    "cv2.circle(drawing_img, (256, 256), 100, (0, 0, 255), 10)\n",
    "plt.imshow(drawing_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.putText(img, text, org, font, fontSacle, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_img = np.full((512, 512, 3), 255, np.uint8)\n",
    "cv2.putText(drawing_img, 'Hello', (10,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,0,0),5)\n",
    "cv2.putText(drawing_img, 'OpenCV', (10,300), cv2.FONT_HERSHEY_SIMPLEX, 4, (0,0,0),5)\n",
    "plt.imshow(drawing_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Editing Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.cvtColor(img, flag)\n",
    "convert an image to other color space\n",
    "- flag = cv2.COLOR_RGB2BGR : RGB -> BGR\n",
    "- flag = cv2.COLOR_BGR2GRAY : BGR -> Grayscale\n",
    "- flag = cv2.COLOR_BGR2HSV : BGR -> HSV\n",
    "\n",
    "#### cv2.resize(img, dsize, fx, fy, interpolation)\n",
    "resize image\n",
    "- dsize : Manual Size ex) (100,200)\n",
    "- fx : multiple of horizontal size\n",
    "- fy : multiple of vertical size\n",
    "- interpolation : 보간법  ex) cv2.INTER_AREA, cv2.INTER_CUBIC\n",
    "\n",
    "#### cv2.flip(img, flag)\n",
    "flip image\n",
    "- flag = 1 : 좌우\n",
    "- flag = 0 : 상하\n",
    "- flag = -1 : 상하좌우\n",
    "\n",
    "#### cv2.rotate(img, flag)\n",
    "rotate image\n",
    "- flag = cv2.ROTATE_90_CLOCKWISE / cv2.ROTATE_90_COUNTERCLOCKWISE / cv2.ROTATE_180\n",
    "- 90도가 아닌 회전을 원하는 경우 cv2.warpAffine 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt_img2 = cv2.cvtColor(cvt_img, cv2.COLOR_BGR2GRAY)\n",
    "cvt_img2 = cv2.cvtColor(cvt_img2, cv2.COLOR_RGB2BGR)\n",
    "mini_img = cv2.resize(cvt_img, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "expand_img = cv2.resize(cvt_img, (2*cvt_img.shape[1], 2*cvt_img.shape[0]), interpolation = cv2.INTER_CUBIC)\n",
    "flip_img = cv2.flip(cvt_img, 1)\n",
    "rotate_img = cv2.rotate(cvt_img, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "titles = [\"ORIGINAL\", \"GRAY\", \"MINI\", \"EXPAND\", \"FLIP\", \"ROTATE\"]\n",
    "imgs = [cvt_img, cvt_img2, mini_img, expand_img, flip_img, rotate_img]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3, i+1)\n",
    "    plt.imshow(imgs[i])\n",
    "    plt.title(titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Save Image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.imwrite(filename, image)\n",
    "Use the function cv.imwrite() to save an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_img = cv2.cvtColor(drawing_img, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('HelloOpenCV.jpg', drawing_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_img_color = cv2.imread('./data/soccer_player.jpg', 1)\n",
    "# player_img_color = cv2.imread('https://i.ytimg.com/vi/wdufu2MKz7Q/hqdefault.jpg', 1)\n",
    "player_img_color = cv2.cvtColor(player_img_color, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(player_img_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = cv2.imread(\"data/soccer_player_gray.jpg\")\n",
    "plt.imshow(gray_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <to do> - convert image to grayscale/drawing rectagle at face-white/put Text his name on the rectangle\n",
    "player_img = cv2.imread('./data/soccer_player.jpg', 0)\n",
    "player_img = cv2.cvtColor(player_img, cv2.COLOR_BGR2RGB)\n",
    "cv2.rectangle(player_img, (220, 50), (290,145), (255,255,255), 5)\n",
    "cv2.putText(player_img, 'Park Jisung', (220, 40), cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),3)\n",
    "plt.imshow(player_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < Getting Started with Videos >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.VideoCaputer(filename or device index)\n",
    "Create a VideoCapture object to capture a video.\n",
    "\n",
    "Device index is just the number to specify which camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cap.get(propId) \n",
    "Access some of the features of this video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"./data/Megamind.avi\")\n",
    "videoWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "videoHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "frameCount = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(\"width :\", videoWidth)\n",
    "print(\"height :\", videoHeight)\n",
    "print(\"frame count :\", frameCount)\n",
    "print(\"fps :\", fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ret, img = cap.read()\n",
    "read image from the video Object\n",
    "- ret : whether image is readable or not (Boolean)\n",
    "- img : image object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, image = cap.read()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.VideoWriter(outputFile, fourcc, fps, size)\n",
    "Create a VideoWriter object to write a video.\n",
    "\n",
    "- outputFile (str) – file name \n",
    "- fourcc – Codec information. cv2.VideoWriter_fourcc()\n",
    "- frame (float) – the value of fps\n",
    "- size (list) – size (ex; 640, 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc =  cv2.VideoWriter_fourcc(*'DIVX')\n",
    "size = (int(videoWidth/2), int(videoHeight/2))\n",
    "print(size)\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 24, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### out.write(image)\n",
    "save the image into video object.\n",
    "\n",
    "#### out.release()\n",
    "Finish to save the video object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "        \n",
    "    frame = cv2.resize(frame, size)\n",
    "    frame = cv2.flip(frame, 0)\n",
    "    cv2.rectangle(frame, (30, 30), (100, 100), (255, 0, 0), 5)\n",
    "    out.write(frame)\n",
    "    \n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < Access pixel values and modify >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_img = cv2.imread(data_path + 'blox.jpg', 1)\n",
    "block_img = cv2.cvtColor(block_img, cv2.COLOR_BGR2RGB)\n",
    "print(block_img.shape)\n",
    "plt.imshow(block_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(block_img[79:132, 170:206, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_img[79:132, 170:206,:] = block_img[79,170,:]\n",
    "plt.imshow(block_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_img = cv2.imread(data_path+'baseball_player.jpg')\n",
    "baseball_img = cv2.cvtColor(baseball_img, cv2.COLOR_BGR2RGB)\n",
    "print(baseball_img.shape)\n",
    "plt.imshow(baseball_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do : Make it look like two balls\n",
    "# ball [305:332, 614:641]\n",
    "baseball_img = cv2.imread(data_path+'baseball_player.jpg')\n",
    "baseball_img = cv2.cvtColor(baseball_img, cv2.COLOR_BGR2RGB)\n",
    "baseball_img[345:372, 614:641, :]= baseball_img[305:332, 614:641, :]\n",
    "plt.imshow(baseball_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < Image Thresholding >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![threshold_info.png](data/threshold_info.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.threshold(src, thresh, maxval, type) → retval, dst \n",
    "If pixel value is greater than a threshold value, it is assigned one value (may be white), else it is assigned another value (may be black).\n",
    " \n",
    "- thresholding type\n",
    "- threshold_value : 픽셀 문턱값\n",
    "- Value : 픽셀 문턱값보다 클 때 적용되는 최대값\n",
    "\n",
    "cv2.THRESH_BINARY : Threshold보다 크면 Value, 아니면 0\n",
    "\n",
    "cv2.THRESH_BINARY_INV : Threshold보다 크면 0이고 아니면 Value\n",
    "\n",
    "cv2.THRESH_TRUNC : Threshold보다 크면 threshold_value, 작으면 픽셀 값\n",
    "\n",
    "cv2.THRESH_TOZERO : Threshold보다 크면 픽셀값, 작으면 0\n",
    "\n",
    "cv2.THRESH_TOZERO_INV : Threshold보다 크면 0, 작으면 픽셀값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_img = cv2.imread(data_path + \"gradient.png\", 1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(gradient_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ret, thresh1 = cv2.threshold(gradient_img, 127, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(gradient_img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(gradient_img, 127, 255, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold(gradient_img, 127, 255, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold(gradient_img, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = [\"Original\", \"Binary\", \"Binary_inv\", \"Trunc\", \"ToZero\", \"ToZero_inv\"]\n",
    "imgs = [gradient_img, thresh1, thresh2, thresh3 ,thresh4, thresh5]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3, i+1)\n",
    "    plt.imshow(imgs[i])\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C)\n",
    "\n",
    "- Adaptive Method\n",
    "\n",
    "cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "\n",
    "cv2.ADAPTIVE_THRESH_GAUSSIAN_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sudoku_img = cv2.imread(data_path + 'sudoku.png',0)\n",
    "\n",
    "ret, th1 = cv2.threshold(sudoku_img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "th2 = cv2.adaptiveThreshold(sudoku_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 2)\n",
    "\n",
    "th3 = cv2.adaptiveThreshold(sudoku_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 2)\n",
    "\n",
    "titles = ['Original','Global','Mean','Gaussian']\n",
    "images = [sudoku_img, th1, th2, th3]\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(10,10))\n",
    "sudoku_img = cv2.cvtColor(sudoku_img, cv2.COLOR_BGR2RGB)\n",
    "th1 = cv2.cvtColor(th1, cv2.COLOR_BGR2RGB)\n",
    "th2 = cv2.cvtColor(th2, cv2.COLOR_BGR2RGB)\n",
    "th3 = cv2.cvtColor(th3, cv2.COLOR_BGR2RGB)\n",
    "ax1.set_title('Original')\n",
    "ax1.imshow(sudoku_img)\n",
    "\n",
    "ax2.set_title('Global')\n",
    "ax2.imshow(th1)\n",
    "\n",
    "ax3.set_title('Mean')\n",
    "ax3.imshow(th2)\n",
    "\n",
    "ax4.set_title('Gaussian')\n",
    "ax4.imshow(th3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### otsu binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lena_img_c = cv2.imread(data_path+\"lena_noisy.jpg\", 1)\n",
    "\n",
    "lena_img = cv2.imread(data_path+\"lena_noisy.jpg\", 0)\n",
    "\n",
    "ret1, th = cv2.threshold(lena_img, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ret2, otsu1 = cv2.threshold(lena_img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "blur = cv2.GaussianBlur(lena_img, (5,5),0)\n",
    "ret, otsu2 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "print(ret1, ret2)\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(10,10))\n",
    "\n",
    "lena_img_c = cv2.cvtColor(lena_img_c, cv2.COLOR_BGR2RGB) \n",
    "th = cv2.cvtColor(th, cv2.COLOR_BGR2RGB)\n",
    "otsu1 = cv2.cvtColor(otsu1, cv2.COLOR_BGR2RGB)\n",
    "otsu2 = cv2.cvtColor(otsu2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "ax1.imshow(lena_img_c)\n",
    "ax2.imshow(th)\n",
    "ax3.imshow(otsu1)\n",
    "ax4.imshow(otsu2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Image Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## < Blurring >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.filter2D(img, ddepth, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(data_path + \"lena.jpg\")\n",
    "gray_img = cv2.imread(data_path + \"lena.jpg\", 0)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.ones((3,3), np.uint8)\n",
    "k = k/(3*3)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_dst = cv2.filter2D(img, -1, k) # -1 : 입력영상과 동일한 크기의 이미지로 출력\n",
    "plt.imshow(blur_dst) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### cv2.Blur(img, ksize)\n",
    "#### cv2.GaussianBlur(img, ksize, sigma)\n",
    "#### cv2.medianBlur(img, ksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dst1 = cv2.blur(img,(7,7))\n",
    "dst2 = cv2.GaussianBlur(img,(5,5),0)\n",
    "dst3 = cv2.medianBlur(img,9)\n",
    "\n",
    "images = [img,dst1,dst2,dst3]\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize =(12,12))\n",
    "axs = [ax1, ax2, ax3, ax4]\n",
    "\n",
    "for i in range(4):\n",
    "    axs[i].imshow(images[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < Motion blur >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size= 5\n",
    "motion_blur = np.zeros((size, size))\n",
    "motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "motion_blur = motion_blur / size\n",
    "\n",
    "#print(motion_blur)\n",
    "dst = cv2.filter2D(img, -1, motion_blur)\n",
    "plt.imshow(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < Sharpening >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpening_1 = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "sharpening_2 = np.array([[-1, -1, -1, -1, -1],\n",
    "                         [-1, 2, 2, 2, -1],\n",
    "                         [-1, 2, 9, 2, -1],\n",
    "                         [-1, 2, 2, 2, -1],\n",
    "                         [-1, -1, -1, -1, -1]]) / 9.0\n",
    "#sharpening 주변 값을 어느정도는 사용한다 -> Noise 가 안생기게 된다.\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize= (14,8))\n",
    "dst1 = cv2.filter2D(img, -1, sharpening_1)\n",
    "ax1.imshow(dst1)\n",
    "\n",
    "dst2 = cv2.filter2D(img, -1, sharpening_2)\n",
    "ax2.imshow(dst2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_edu2",
   "language": "python",
   "name": "cv_edu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
